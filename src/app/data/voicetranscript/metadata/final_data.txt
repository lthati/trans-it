SPEAKER: F1
My name is Cragg. I'm a researcher at Google and I work for the auto project.
SPEAKER: M1
And I'm gemmen by design on the team. How are you guys doing.
SPEAKER: F1
And we're going to talk about designing for driving.
SPEAKER: M3
So Manono explain what that actually means. So what we want to do is we want to give you a little bit of an insight of how it came about to the considerations that went into making it and how we're supporting developers who might not know all even about automotive design in bringing their Android up to this new platform. And then time permitting we want to talk a little bit about the future as well.
SPEAKER: M9
So Android Auto. Does everybody know what it is. Anybody not know what it is. OK. I think everybody knows. But for those that don't know it's an extension of Android bringing Android into the car. So you get the apps the functionality the features that you want from your phone but you haven't presented in a new manner that's fit for the context of driving.
SPEAKER: M3
Why are we on and on automotive areas. Well if you heard someone this morning talk about the whole large platform of Android we're really a big part of that Android is all about having many touch points into people's lives across devices not just phones not just tablets but also watches cars and TV. And this is all for over a billion users and a whole ecosystem on top of it. The new developers help us build this wall and together we make it really like a really big thing. And as of today as at or 2016 we're talking about Android itself becoming a platform that has two new form factors in addition to what was already on the market for about a year spending a wider range of automotive types and actually you know really becoming a system itself. And the first one the first form factor I want to talk about is the one that we already saw in the photo which is the by plugging your phone into a comfortable car and then your phone becomes projected directly onto the cost display and you use the cost control to interact with your content.
SPEAKER: M7
And so this is powering the phone is powering the entire experience in this in this form factor. And as of 2016 as of today Android autos are also previewing a brand new form factor for those cars that are not yet comfortable with the plug in version of Android. So we are extending into these older cars for example if you have a classic an engine you want to put Bluetooth in. This is a great and your audio experience directly on the phone screen. So you dont need anything else there. And the third thing we want to preview is really a concept of Android as an embedded platform built directly into the car. This is you can see this outside in the red Maserati theres a preview of that concept there and its common in pictures can actually build their native system on top of Android and so you can get a great experience directly built into the car. And what were super spodes to see as I was you know having built the system is finally realizing this bigger vision of Android Auto being running across all these different platforms and translating the UI depending on the screen from Prockter depending on the input devices that your house and I think this is something that we are super excited about. And Greg is now shedding more light on why driving is really so different than using your regular phone in a regular context.
SPEAKER: M2
Right. So when we go when we move into new spaces its really important to take the context of the environment into account when we look at driving today we see that we're spending a lot of time inside the car.
SPEAKER: M9
So from a fairly recent study they found that the average person in the U.S. spends around 45 minutes inside the car per day. For those of us living in the Bay Area it's actually probably higher given the traffic volumes that we have here. But either way that's somewhere on the magnitude of around 280 hours per year inside the car.
SPEAKER: M4
A lot of time and it's a lot of it's a big piece of our life. And what we find is that during that time people don't want to necessarily stop there to enjoy life.
SPEAKER: M6
So they want to still be able to be entertained. They want to communicate they want to be productive. And if we can find out if we can't figure out the right way to convey the information then it leads to problems. So as an example texting we we all know that texting isn't good. A study has found that they noted at highway speeds when you text and drive it's approximately equivalent to driving the length of a football field while not looking at the roadway. So it's not good. And we know that we shouldn't do it yet we also know that people are still doing it.
SPEAKER: F2
So the question is why.
SPEAKER: M6
Well one reason is that we tend to overestimate our driving abilities. So as drivers we're generally overconfident and we we tend to try and we don't understand the true dangers. So basically we were overconfident with our abilities and we also underestimate the true dangers of driving. This leads to a pretty bad mix because when we want to engage with what we want to be productive or communicate or be entertained it means that we will start to. We start to engage with our phone or do things that we shouldn't necessarily do. And the problem is when we're driving if we screw up or you do something stupid you don't just put yourself at risk but you put all those others in the car with your risk and you put those around you risk as well. So it's really critical that we figure out how to re-examine the technology to better suit the environment.
SPEAKER: M10
Did you in fact have a statistic where you said that the majority of drivers think they are better than average drivers which is actually mathematically impossible.
SPEAKER: M2
Yeah yeah it was somewhere around I think it was 93 percent of those sampled thought they are above average drivers.
SPEAKER: M10
And the rest of us was probably a statistic expert that realized that wasn't possible.
SPEAKER: M7
So from this point it's really really clear that the phone in designing for the phone is not the same thing as designing for driving really two different things. I think Greg has made abundantly clear with the three points that he just made that it's a very different situation and this different environment need to be thought of as such.
SPEAKER: M1
When we start about designing apps and services for this environment.
SPEAKER: M2
Right. And one thing to note is it's not massively the phones fault. If you go into a car dealership today and you look at the technology that's going inside the cards a lot of them resemble tablets and phones right. So it's not just the technology but again it's the way that the information is constructed and ultimately conveyed.
SPEAKER: F2
That's the critical elements.
SPEAKER: M7
And so find it out. And this is what this Tarkas is about the experience needs to be designed specifically for driving. And what this means we're going to start with the next few slides. So for one thing one easy way that we can think of this is that really drive driving and keeping our eyes on the road is task number one. And dealing with the fall and should be tossed number two. And this is very different than.
SPEAKER: M1
Phones were designed specifically for full engagement for full engagement. And here we actually want to do it differently because we don't want you to spend this much time with the eyes of the road.
SPEAKER: M2
And another way to think about this is if you substitute prior task for driving and your secondary task is a distraction. So all other activities inside the car that don't pertain to driving are in fact distracting and we find that people engage in distracting activities quite a lot. So there's a recent study that looked at naturalistic driving data and found that over 50 percent of the time people engage in destructive activities. This this can be anything from texting. So we talked about before but it can also be E.T. or conversing with the passenger or even dancing in your car seat. So all of this if it doesn't pertain to driving it has some element of distraction for the driving task. Well we look at distractions so if we can break it down from the human perspective we see that ultimately can be thought of in three main fundamental ways. So we have visual distraction. This is of course when your eyes are off the road looking at other things we can have manual distraction and this is here when your hands are off the steering wheel or steering controls fidgeting with other things like the climate control that we can have cognitive distraction. This one's a little bit harder to assess but it's basically when your mind is not actively thinking about the driving task and is attending to other things in the real world we we don't we rarely see a task that takes just one form of destruction. Most often tasks have some element of all of these types of disruption. So if we use an example something as simple as rolling up the window in order to determine if you need to roll up the window you might have to glance at the window. So there's some visual you have to reach over to the button of course so there's some manual distraction and then you have to think about maybe you need to push or do I need to pull on. So this is a really simplified example and of course the levels of distraction here aren't really critical but it's a good representation and it's a good. It helps us to understand when we're designing experiences we need to figure out how can we. Focus the experience. How do the experiences affect each of the different channels of the interaction. Ultimately how can we minimize the overall destruction and what we know is that we can't fully eliminate it. Distractions always going to exist in some form inside the car. But what we can do is we can mitigate it through a responsible design.
SPEAKER: M1
So then how do we fundamentally rethink how we design that you know if we're driving away from the interaction model that we know from the handheld. And what I want to do is actually share a few principles with you that have come about as we did a lot of research and a lot of design iterations. And let's talk about those. So. One simple principle that is sort of one of the foundations 100.0 is that we're really trying to biasing things to its action. What does this mean. So when you on your phone and trying to play music for example you have a selection of multiple apps. You select your app then you have maybe a grid of like definite differences just suggested things. Some song you might not be in there. You're scrolling down a list maybe possibly another list and that's a lot of noodling before you actually get to play a song. Compare this with the old style auto radio. If you still remember those from way back when we had just press any of the buttons and outcome's music. It's really simple when you put it in a CD or cassette and just works. And this is sort of the gold standard in some ways because you know there's very little load on you. You just started and Amelie's actionable e-media is set up for consumption and then you can still change from there. You know the channel whatever but it gives you some instant gratification.
SPEAKER: M4
Write and then we also want to try and reduce visual and cognitive load by overall simplifying the interface and making layouts and content predictable. So making things consistent and then slamming the hierarchies as much as we can to make against surface actions as quickly as possible. So this really overall just means a reduction in complexity and really focusing on core activities that make sense to do while driving. And keep in mind for other activities those can always be deferred too pre or post strifes states such as playing with or playing with settings. All of this is time to keep interactions efficient so that you can get the content you want. That thing gets back to driving as quickly as possible. And for those other tasks where you're looking for very specific content voice it can be a great shortcut. It can be this great deep dive. So if you're looking for that one song that you really want to play you can simply make a voice command. And this allows you to reroute away from the complexity of going through an interface visually and just make a simple voice command and get it. So we really want to enable voice in all of our apps so that users can take advantage of these shortcuts and the great thing is about Hoy's is it really doesn't require any visual elements or manual elements for destruction. We're also talking today if you go over to the booth later on you'll see that we're working on hoardings so that. OK Google will work in the car so you don't actually have to press the button as well to start your voice session. Now the other side of this is though we can alleviate visual and manual distraction. We do have to be aware that in voice comes at a cost through cognitive distraction because every time you think about what you're going to say every time you start to speak and every time you listen it takes some element of cognitive processing. So we want to carefully design the voice voice interfaces and the voice flows to try and mitigate cognitive processing and overall cognitive flown.
SPEAKER: M1
So people asked us often why don't you just use your phone capable of using it today. Right. And the phone had 10 years the last 10 years is really off to almost like a computing platform of smartphones and it really has had a long time to optimize since you. But think about it when you're driving. Your attention is primarily on the road and your phone will be an arm's length away from you not close to you. And then finally if you haven't driven on the American highways around here you know there's a ton of potholes and you know what that does to your touch accuracy. You know if you ever done tried those on the screen it's very very tricky. And then you throw in non ideal lighting conditions like today when the car turns the light comes from the side and from this side sometimes the phone is full of glare and you can't really see anything and you can't change any of these things.
SPEAKER: M8
Right. And so it becomes clear that we don't have a regular handset situation here. So first of all it's a tough struggle. He needs to be significant large or just see in the distance the touch target seems to be much more forgiving and bigger. And then finally the contrast needs to be maximized to work in all the lighting conditions including night driving. The good news is with every building blocks that we're making for the OS We're also keeping that developers in mind as we're building this so you don't have to necessarily spend all these details you don't have to be caught and driving explodes as you're building an app finder in auto. So a few examples on the left side we have fun styles that have been extensively tested and optimized for driving use case that all of us can call upon. We have layouts and component sizes builds for automotive touch target sizes so all of the arts are actually built on this sort of metric that allows for these large enough touch targets. And then finally we have this I can contrast switch a mechanism built into the system where you can provide an icon as an app developer. That's one one color. And then we switch the color accordingly to what happens with the background. And this happens automatically.
SPEAKER: F2
You don't have to worry about that.
SPEAKER: M4
So this is the whole field of legibility in Glaspell environments is actually super super interesting area. And what you find is that little tweaks and things like font way or font size or contrasts can actually have quite significant impact on the overall readability and time it takes to understand or read text. And so you know when we're talking about